{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a Glass Identification Data Set from UCI. It contains 10 attributes including id. The response is glass type(discrete 7 values)\n",
    "\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Id number: 1 to 214 (removed from CSV file)\n",
    "RI: refractive index\n",
    "Na: Sodium (unit measurement: weight percent in the corresponding oxide, as attributes 4-10)\n",
    "Mg: Magnesium\n",
    "Al: Aluminum\n",
    "Si: Silicon\n",
    "K: Potassium\n",
    "Ca: Calcium\n",
    "Ba: Barium\n",
    "Fe: Iron\n",
    "Type of glass: (class attribute)\n",
    "-- 1 buildingwindowsfloatprocessed\n",
    "\n",
    "-- 2 buildingwindowsnonfloatprocessed\n",
    "\n",
    "-- 3 vehiclewindowsfloatprocessed\n",
    "-- 4 vehiclewindowsnonfloatprocessed (none in this database)\n",
    "-- 5 containers\n",
    "-- 6 tableware\n",
    "-- 7 headlamps\n",
    "\n",
    "\n",
    "\n",
    "Perform multi-class classification using neural networks to predict glass type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"glass.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
       "\n",
       "[214 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      0\n",
       "Na      0\n",
       "Mg      0\n",
       "Al      0\n",
       "Si      0\n",
       "K       0\n",
       "Ca      0\n",
       "Ba      0\n",
       "Fe      0\n",
       "Type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    76\n",
       "1    70\n",
       "7    29\n",
       "3    17\n",
       "5    13\n",
       "6     9\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"Type\", axis=1)\n",
    "y = df[\"Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y) #stratify means equaliy divide train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    53\n",
       "1    49\n",
       "7    20\n",
       "3    12\n",
       "5     9\n",
       "6     6\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    23\n",
       "1    21\n",
       "7     9\n",
       "3     5\n",
       "5     4\n",
       "6     3\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Dense(2, activation=\"relu\", input_shape=(x.shape[1],)),\n",
    "     tf.keras.layers.Dense(5, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(8, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 641us/step - loss: 1.9145\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 712us/step - loss: 1.8589\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.8607\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.8750\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 997us/step - loss: 1.8636\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 997us/step - loss: 1.7554\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 712us/step - loss: 1.6817\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.7441\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6032\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.5926\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.7620\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.6673\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6209\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.7562\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6507\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.6781\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 642us/step - loss: 1.6095\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 641us/step - loss: 1.7569\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 712us/step - loss: 1.6316\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 712us/step - loss: 1.6577\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6368\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.6903\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6575\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 997us/step - loss: 1.6210\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.5100\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.5592\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6997\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 784us/step - loss: 1.5758\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 641us/step - loss: 1.7311\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 641us/step - loss: 1.6039\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 570us/step - loss: 1.5009\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 997us/step - loss: 1.5330\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 927us/step - loss: 1.5112\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 784us/step - loss: 1.5507\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6563\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6524\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6098\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.6178\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 855us/step - loss: 1.5158\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.5082\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 926us/step - loss: 1.5936\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.673 - 0s 712us/step - loss: 1.5526\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 784us/step - loss: 1.5418\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 641us/step - loss: 1.6275\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 784us/step - loss: 1.4866\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6128\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.6386\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4447\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.4740\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 997us/step - loss: 1.5939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x270f1290040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01783166, 0.3342196 , 0.3650139 , 0.06897898, 0.00692977,\n",
       "        0.04720223, 0.02509435, 0.13472947],\n",
       "       [0.02087367, 0.32366467, 0.3497539 , 0.07579865, 0.00873555,\n",
       "        0.05342462, 0.02988615, 0.13786294],\n",
       "       [0.01931141, 0.32904357, 0.35744807, 0.07236549, 0.00778955,\n",
       "        0.05026086, 0.02741337, 0.13636765],\n",
       "       [0.01900035, 0.33012486, 0.35901487, 0.07166486, 0.00760587,\n",
       "        0.04962305, 0.02692398, 0.13604213],\n",
       "       [0.01747189, 0.33549076, 0.36689854, 0.06813447, 0.00672613,\n",
       "        0.04644896, 0.02453405, 0.13429528],\n",
       "       [0.02261776, 0.31775552, 0.34147674, 0.07947318, 0.00983739,\n",
       "        0.05688262, 0.03267514, 0.13928184],\n",
       "       [0.03060175, 0.29179484, 0.30684727, 0.09448954, 0.01548534,\n",
       "        0.07184162, 0.04579498, 0.14314467],\n",
       "       [0.01984082, 0.32721123, 0.35480878, 0.07354465, 0.00810576,\n",
       "        0.05134029, 0.02824858, 0.13689984],\n",
       "       [0.0193777 , 0.32881352, 0.35711572, 0.07251405, 0.0078289 ,\n",
       "        0.05039645, 0.0275178 , 0.13643578],\n",
       "       [0.01903979, 0.3299876 , 0.35881552, 0.07175402, 0.00762907,\n",
       "        0.04970408, 0.02698598, 0.13608396],\n",
       "       [0.01905521, 0.32993394, 0.35873765, 0.07178887, 0.00763815,\n",
       "        0.04973575, 0.02701023, 0.13610028],\n",
       "       [0.0195624 , 0.32817367, 0.35619262, 0.07292659, 0.0079389 ,\n",
       "        0.05077357, 0.02780899, 0.13662334],\n",
       "       [0.01859432, 0.3315417 , 0.3610786 , 0.07074147, 0.00736846,\n",
       "        0.04878644, 0.02628669, 0.13560252],\n",
       "       [0.02032042, 0.32555982, 0.35244647, 0.07459879, 0.00839608,\n",
       "        0.05231163, 0.02900767, 0.13735908],\n",
       "       [0.01911911, 0.32971165, 0.35841522, 0.07193305, 0.00767582,\n",
       "        0.04986689, 0.02711072, 0.13616757],\n",
       "       [0.01831015, 0.33253688, 0.36253563, 0.07008909, 0.00720389,\n",
       "        0.04819814, 0.0258417 , 0.13528456],\n",
       "       [0.01921954, 0.32936257, 0.35790956, 0.07215919, 0.00773515,\n",
       "        0.05007279, 0.02726874, 0.13627253],\n",
       "       [0.017736  , 0.33455712, 0.3655132 , 0.06875526, 0.00687542,\n",
       "        0.04700232, 0.02494523, 0.13461547],\n",
       "       [0.01858116, 0.33158767, 0.3611457 , 0.07071136, 0.00736081,\n",
       "        0.04875925, 0.02626606, 0.13558795],\n",
       "       [0.02053465, 0.32482472, 0.35139978, 0.07506543, 0.00852695,\n",
       "        0.05274355, 0.02934748, 0.1375574 ],\n",
       "       [0.0193951 , 0.32875323, 0.35702854, 0.07255299, 0.00783924,\n",
       "        0.05043202, 0.02754521, 0.13645358],\n",
       "       [0.02081816, 0.3238543 , 0.35002246, 0.07567904, 0.00870127,\n",
       "        0.05331332, 0.02979789, 0.1378136 ],\n",
       "       [0.0199042 , 0.32699257, 0.3544951 , 0.07368471, 0.00814391,\n",
       "        0.051469  , 0.02834876, 0.13696176],\n",
       "       [0.01905825, 0.32992336, 0.35872233, 0.07179573, 0.00763994,\n",
       "        0.04974199, 0.027015  , 0.13610348],\n",
       "       [0.0190047 , 0.33010972, 0.35899287, 0.07167473, 0.00760843,\n",
       "        0.04963201, 0.02693083, 0.13604677],\n",
       "       [0.02013491, 0.32619768, 0.3533571 , 0.07419261, 0.00828335,\n",
       "        0.05193665, 0.02871378, 0.13718398],\n",
       "       [0.01996773, 0.3267735 , 0.3541811 , 0.07382488, 0.00818222,\n",
       "        0.05159792, 0.02844923, 0.13702345],\n",
       "       [0.01922246, 0.32935244, 0.3578949 , 0.07216574, 0.00773687,\n",
       "        0.05007876, 0.02727332, 0.13627556],\n",
       "       [0.01932897, 0.3289826 , 0.35735995, 0.07240488, 0.00779997,\n",
       "        0.05029681, 0.02744104, 0.13638572],\n",
       "       [0.01997264, 0.32675654, 0.35415682, 0.07383572, 0.00818519,\n",
       "        0.05160788, 0.028457  , 0.1370282 ],\n",
       "       [0.01847729, 0.33195114, 0.36167732, 0.0704734 , 0.00730052,\n",
       "        0.04854443, 0.02610332, 0.13547257],\n",
       "       [0.01879429, 0.33084312, 0.36005944, 0.07119752, 0.00748505,\n",
       "        0.04919907, 0.02660035, 0.13582113],\n",
       "       [0.01893565, 0.33035028, 0.3593423 , 0.07151839, 0.00756786,\n",
       "        0.04949006, 0.02682231, 0.13597322],\n",
       "       [0.0188175 , 0.33076212, 0.35994154, 0.0712503 , 0.00749863,\n",
       "        0.04924688, 0.02663678, 0.13584627],\n",
       "       [0.02055027, 0.3247712 , 0.35132366, 0.07509935, 0.00853652,\n",
       "        0.052775  , 0.02937227, 0.1375717 ],\n",
       "       [0.01795908, 0.33377063, 0.36435083, 0.06927606, 0.00700241,\n",
       "        0.0474681 , 0.02529313, 0.13487975],\n",
       "       [0.0200357 , 0.32653925, 0.3538457 , 0.07397459, 0.00822328,\n",
       "        0.05173573, 0.02855675, 0.13708903],\n",
       "       [0.01870565, 0.3311526 , 0.36051056, 0.07099568, 0.00743329,\n",
       "        0.04901632, 0.02646126, 0.13572475],\n",
       "       [0.01938018, 0.32880506, 0.35710338, 0.0725196 , 0.00783037,\n",
       "        0.05040152, 0.02752171, 0.13643833],\n",
       "       [0.02213023, 0.31939757, 0.34375957, 0.07846203, 0.00952456,\n",
       "        0.05592354, 0.03189258, 0.13890997],\n",
       "       [0.02026235, 0.32575935, 0.35273114, 0.07447185, 0.00836073,\n",
       "        0.05219434, 0.02891563, 0.13730459],\n",
       "       [0.01959552, 0.328059  , 0.35602745, 0.07300036, 0.00795869,\n",
       "        0.0508411 , 0.02786125, 0.13665661],\n",
       "       [0.02180303, 0.32050377, 0.34530476, 0.07777657, 0.00931671,\n",
       "        0.05527664, 0.03136865, 0.13864985],\n",
       "       [0.0203999 , 0.32528695, 0.35205758, 0.07477221, 0.00844455,\n",
       "        0.052472  , 0.02913368, 0.13743314],\n",
       "       [0.01997562, 0.32674626, 0.35414213, 0.07384226, 0.00818699,\n",
       "        0.05161392, 0.0284617 , 0.13703106],\n",
       "       [0.01837643, 0.33230445, 0.36219475, 0.07024172, 0.00724216,\n",
       "        0.04833557, 0.02594543, 0.13535947],\n",
       "       [0.01828416, 0.33262804, 0.36266944, 0.07002918, 0.00718891,\n",
       "        0.04814422, 0.02580105, 0.13525504],\n",
       "       [0.02483672, 0.3103712 , 0.3313615 , 0.08392749, 0.0113081 ,\n",
       "        0.06117724, 0.03626488, 0.1407528 ],\n",
       "       [0.01734408, 0.33594355, 0.36757246, 0.06783237, 0.0066543 ,\n",
       "        0.04618042, 0.02433535, 0.13413744],\n",
       "       [0.01997479, 0.3267492 , 0.3541463 , 0.07384044, 0.00818648,\n",
       "        0.05161223, 0.02846039, 0.13703027],\n",
       "       [0.01714098, 0.33666447, 0.36864853, 0.06735006, 0.00654071,\n",
       "        0.04575267, 0.02401995, 0.13388267],\n",
       "       [0.02059894, 0.32460445, 0.35108674, 0.07520498, 0.00856637,\n",
       "        0.05287294, 0.02944954, 0.13761614],\n",
       "       [0.0410188 , 0.259999  , 0.26723137, 0.11052875, 0.02434607,\n",
       "        0.08955885, 0.06370587, 0.14361137],\n",
       "       [0.01978277, 0.32741168, 0.35509655, 0.07341615, 0.00807086,\n",
       "        0.05122229, 0.02815685, 0.13684277],\n",
       "       [0.01928099, 0.32914916, 0.35760075, 0.07229722, 0.00777152,\n",
       "        0.05019862, 0.02736547, 0.13633625],\n",
       "       [0.01986031, 0.327144  , 0.3547123 , 0.07358774, 0.00811748,\n",
       "        0.05137988, 0.02827938, 0.13691892],\n",
       "       [0.01954534, 0.32823274, 0.3562777 , 0.07288855, 0.00792872,\n",
       "        0.05073877, 0.02778207, 0.13660616],\n",
       "       [0.01892225, 0.33039686, 0.3594101 , 0.07148805, 0.00756   ,\n",
       "        0.04946251, 0.02680127, 0.1359589 ],\n",
       "       [0.01937628, 0.32881853, 0.35712284, 0.07251087, 0.00782806,\n",
       "        0.05039355, 0.02751557, 0.13643432],\n",
       "       [0.01855249, 0.33168793, 0.36129227, 0.07064575, 0.00734416,\n",
       "        0.0487    , 0.02622114, 0.13555622],\n",
       "       [0.0187673 , 0.33093733, 0.3601967 , 0.07113612, 0.00746928,\n",
       "        0.04914346, 0.026558  , 0.13579187],\n",
       "       [0.03159827, 0.28866264, 0.30282632, 0.09618253, 0.0162594 ,\n",
       "        0.07361872, 0.04747079, 0.14338137],\n",
       "       [0.01909806, 0.32978487, 0.3585214 , 0.07188559, 0.0076634 ,\n",
       "        0.04982371, 0.02707761, 0.13614546],\n",
       "       [0.01239049, 0.3540496 , 0.39590853, 0.05516841, 0.00408395,\n",
       "        0.03535024, 0.01678111, 0.1262677 ],\n",
       "       [0.01744643, 0.3355809 , 0.36703253, 0.06807437, 0.0067118 ,\n",
       "        0.0463955 , 0.02449445, 0.13426398]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index number of the maximum value\n",
    "y_hat1 = y_hat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.35      1.00      0.52        23\n",
      "           3       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.35        65\n",
      "   macro avg       0.06      0.17      0.09        65\n",
      "weighted avg       0.13      0.35      0.18        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
